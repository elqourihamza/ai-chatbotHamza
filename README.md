# Azure RAG Chatbot

Application de chatbot RAG (Retrieval-Augmented Generation) utilisant Azure OpenAI, Pinecone et LangChain.

## ğŸ“‹ PrÃ©requis

- Python 3.9 ou supÃ©rieur
- Un compte Azure avec accÃ¨s Ã  Azure OpenAI
- Un compte Pinecone
- pip (gestionnaire de paquets Python)

## ğŸš€ Installation et Configuration

### 1. Cloner le projet

```bash
git clone https://github.com/OUCHAALI/azure-rag-chatbot.git
cd azure-rag-chatbot
```

### 2. CrÃ©er un environnement virtuel (recommandÃ©)

```powershell
# CrÃ©er l'environnement virtuel
python -m venv venv

# Activer l'environnement virtuel
.\venv\Scripts\Activate.ps1
```

### 3. Installer les dÃ©pendances

#### Backend
```powershell
cd backend
pip install -r requirements.txt
cd ..
```

#### Frontend
```powershell
cd frontend
pip install -r requirements.txt
cd ..
```

### 4. Configuration des variables d'environnement

CrÃ©ez un fichier `.env` dans le dossier `backend` avec vos clÃ©s API :

```env
# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=votre_cle_azure_openai
AZURE_OPENAI_ENDPOINT=https://votre-endpoint.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-12-01-preview
AZURE_CHAT_DEPLOYMENT=o4-mini
AZURE_EMBEDDING_DEPLOYMENT=text-embedding-ada-002

# Pinecone Configuration
PINECONE_API_KEY=votre_cle_pinecone
PINECONE_CLOUD=aws
PINECONE_ENV=us-east-1
PINECONE_INDEX_NAME=rag-workshop-azure
PINECONE_NAMESPACE=
PINECONE_DIMENSION=1536
```

> ğŸ’¡ Un fichier `.env.example` est disponible dans le dossier `backend` comme rÃ©fÃ©rence.
> âš ï¸ Le fichier `.env` contient vos clÃ©s secrÃ¨tes et est ignorÃ© par Git (`.gitignore`)

## â–¶ï¸ Lancement de l'application

Vous devez lancer **deux terminaux sÃ©parÃ©s** :

### ğŸš€ Option 1 : Avec les scripts PowerShell (RecommandÃ©)

**Terminal 1 : Backend**
```powershell
.\start-backend.ps1
```

**Terminal 2 : Frontend**
```powershell
.\start-frontend.ps1
```

### ğŸ”§ Option 2 : Commandes manuelles

**Terminal 1 : DÃ©marrer le backend (API FastAPI)**

```powershell
cd backend
uvicorn app.main:app --reload --host 127.0.0.1 --port 8000
```

Le backend sera accessible sur `http://127.0.0.1:8000`

**Terminal 2 : DÃ©marrer le frontend (Interface Streamlit)**

```powershell
cd frontend
streamlit run ui.py
```

Le frontend s'ouvrira automatiquement dans votre navigateur sur `http://localhost:8501`

> ğŸ“– Consultez le fichier [QUICKSTART.md](QUICKSTART.md) pour un guide dÃ©taillÃ©

## ğŸ“– Utilisation

1. **TÃ©lÃ©charger un PDF** : Utilisez la barre latÃ©rale pour uploader un document PDF
2. **Poser des questions** : Une fois le PDF traitÃ©, posez vos questions dans le chat
3. **Consulter l'historique** : Les conversations sont sauvegardÃ©es et accessibles dans la barre latÃ©rale

## ğŸ—ï¸ Architecture

```
azure-rag-chatbot/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py           # API FastAPI
â”‚   â”‚   â”œâ”€â”€ config.py         # Configuration
â”‚   â”‚   â””â”€â”€ rag_pipeline.py   # Pipeline RAG
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ .env                   # Variables d'environnement (Ã  crÃ©er)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ ui.py                  # Interface Streamlit
â”‚   â””â”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ› ï¸ Technologies utilisÃ©es

- **Backend** : FastAPI, LangChain, Azure OpenAI, Pinecone
- **Frontend** : Streamlit
- **Embeddings** : Azure OpenAI Embeddings
- **Vector Database** : Pinecone
- **LLM** : Azure OpenAI GPT

## ğŸ”§ DÃ©pannage

### Le backend ne dÃ©marre pas
- VÃ©rifiez que toutes les variables d'environnement sont correctement configurÃ©es dans le fichier `.env`
- Assurez-vous que le port 8000 n'est pas dÃ©jÃ  utilisÃ©

### Le frontend ne se connecte pas au backend
- VÃ©rifiez que le backend est bien dÃ©marrÃ© sur `http://127.0.0.1:8000`
- La variable `API_URL` dans `ui.py` est configurÃ©e pour pointer vers `http://127.0.0.1:8000` par dÃ©faut

### Erreurs avec Pinecone
- VÃ©rifiez que votre index Pinecone existe et a la bonne dimension (1536 pour les embeddings Azure)
- VÃ©rifiez vos clÃ©s API Pinecone

## ğŸ“ License

Ce projet est sous licence MIT.
